# MTA KPI Forecasting System - Clean Project Structure# MTA KPI Forecasting System Project Structure



## Directory Organization## Directory Organization



``````

FYP PROJECT/FYP PROJECT/

â”œâ”€â”€ ğŸ“Š dashboard/                # Professional Analytics Dashboardâ”œâ”€â”€ ğŸ“Š src/                      # Core source code

â”‚   â”œâ”€â”€ app.py                   # Streamlit application â­â”‚   â”œâ”€â”€ config.py                # Configuration settings

â”‚   â””â”€â”€ style.css                # Professional Apple-inspired theme â­â”‚   â”œâ”€â”€ eval.py                  # Evaluation metrics

â”‚â”‚   â”œâ”€â”€ features.py              # Feature engineering

â”œâ”€â”€ ğŸ“ˆ data/                     # Dataset storageâ”‚   â”œâ”€â”€ preprocess.py            # Data preprocessing

â”‚   â”œâ”€â”€ raw/                     # Original MTA dataâ”‚   â”œâ”€â”€ train_ml.py              # Optimized ML training pipeline â­

â”‚   â”œâ”€â”€ interim/                 # Cleaned dataâ”‚   â”œâ”€â”€ train_ts.py              # Time series training pipeline â­

â”‚   â””â”€â”€ processed/               # Model-ready data â­â”‚   â””â”€â”€ utils_io.py              # I/O utilities

â”‚       â””â”€â”€ mta_model.parquet    # Final optimized datasetâ”‚

â”‚â”œâ”€â”€ ğŸ¯ dashboard/                # Interactive dashboard

â”œâ”€â”€ ğŸ¤– models/                   # Production Modelsâ”‚   â””â”€â”€ app.py                   # Streamlit application â­

â”‚   â”œâ”€â”€ RandomForest_model.pkl   # Best performer (MAE: 13,637) â­â”‚

â”‚   â”œâ”€â”€ XGBoost_model.pkl        # Secondary model (MAE: 39,885)â”œâ”€â”€ ğŸ“ˆ data/                     # Dataset storage

â”‚   â”œâ”€â”€ LinearRegression_model.pkl # Baseline model (MAE: 130,912)â”‚   â”œâ”€â”€ raw/                     # Original MTA data

â”‚   â””â”€â”€ time_series/             # 264 Prophet & SARIMA modelsâ”‚   â”œâ”€â”€ interim/                 # Cleaned data

â”‚       â”œâ”€â”€ prophet_models.pkl   # Prophet forecasting modelsâ”‚   â””â”€â”€ processed/               # Model-ready data â­

â”‚       â””â”€â”€ sarima_models.pkl    # SARIMA time series modelsâ”‚

â”‚â”œâ”€â”€ ğŸ¤– models/                   # Trained models

â”œâ”€â”€ ğŸ“Š src/                      # Core Source Codeâ”‚   â”œâ”€â”€ RandomForest_model.pkl   # Best performer â­

â”‚   â”œâ”€â”€ config.py                # Configuration settingsâ”‚   â”œâ”€â”€ XGBoost_model.pkl        # Optimized â­

â”‚   â”œâ”€â”€ eval.py                  # Evaluation metricsâ”‚   â”œâ”€â”€ LinearRegression_model.pkl # Baseline

â”‚   â”œâ”€â”€ features.py              # Feature engineering (45 features)â”‚   â””â”€â”€ time_series/             # Prophet & SARIMA models

â”‚   â”œâ”€â”€ preprocess.py            # Data preprocessing pipelineâ”‚

â”‚   â”œâ”€â”€ train_ml.py              # ML training pipeline â­â”œâ”€â”€ ğŸ”¬ scripts/                  # Analysis & utilities

â”‚   â”œâ”€â”€ train_ts.py              # Time series training pipeline â­â”‚   â”œâ”€â”€ analysis/                # Performance analysis

â”‚   â””â”€â”€ utils_io.py              # I/O utilitiesâ”‚   â”œâ”€â”€ optimization/            # Hyperparameter tuning â­

â”‚â”‚   â”œâ”€â”€ data_processing/         # Data preparation

â”œâ”€â”€ ğŸ”¬ scripts/                  # Analysis & Optimizationâ”‚   â””â”€â”€ visualization/           # Chart generation

â”‚   â”œâ”€â”€ analysis/                # Performance analysis toolsâ”‚

â”‚   â”‚   â”œâ”€â”€ analyze_model_performance.py # Model comparison â­â”œâ”€â”€ ğŸ“Š reports/                  # Generated outputs

â”‚   â”‚   â”œâ”€â”€ analyze_optimal_models.py    # Optimization analysisâ”‚   â”œâ”€â”€ eda_summary.md           # Exploratory analysis

â”‚   â”‚   â””â”€â”€ check_model_structure.py     # Model validationâ”‚   â””â”€â”€ figures/                 # Performance charts â­

â”‚   â”œâ”€â”€ optimization/            # Hyperparameter tuningâ”‚

â”‚   â”‚   â”œâ”€â”€ hyperparameter_tuning.py     # General tuningâ”œâ”€â”€ ğŸ“š docs/                     # Documentation

â”‚   â”‚   â””â”€â”€ xgboost_hyperparameter_tuning.py # XGBoost specificâ”‚   â”œâ”€â”€ DASHBOARD_GUIDE.md       # User instructions

â”‚   â””â”€â”€ visualization/           # Chart generationâ”‚   â”œâ”€â”€ DASHBOARD_USER_GUIDE.md  # Detailed guide

â”‚       â”œâ”€â”€ create_performance_graphs.py # Performance charts â­â”‚   â””â”€â”€ MODEL_SELECTION_GUIDE.md # Model recommendations

â”‚       â””â”€â”€ create_training_graphs.py    # Training visualizationâ”‚

â”‚â”œâ”€â”€ ğŸ“ notebooks/                # Jupyter analysis

â”œâ”€â”€ ğŸ“Š reports/                  # Performance Reportsâ”‚   â””â”€â”€ eda.ipynb               # Exploratory data analysis

â”‚   â”œâ”€â”€ model_evaluation_final_report.txt        # Technical evaluation â­â”‚

â”‚   â”œâ”€â”€ model_evaluation_results.csv             # Performance metricsâ”œâ”€â”€ ğŸ“‹ README.md                 # Project overview â­

â”‚   â”œâ”€â”€ model_performance_overview_updated.md    # Executive summary â­â”œâ”€â”€ ğŸ“¦ requirements.txt          # Dependencies

â”‚   â””â”€â”€ figures/                                 # Performance visualizations â­â”œâ”€â”€ ğŸš€ run_dashboard.bat         # Quick startup â­

â”‚       â”œâ”€â”€ ml_model_performance.pngâ””â”€â”€ âš™ï¸ Makefile                 # Build automation

â”‚       â”œâ”€â”€ model_ecosystem_summary.png```

â”‚       â”œâ”€â”€ model_evaluation_comprehensive.png

â”‚       â”œâ”€â”€ model_selection_flow.png### **Core Implementation**

â”‚       â”œâ”€â”€ performance_table.png- **`src/train_ml.py`** - Main ML training with optimized hyperparameters

â”‚       â””â”€â”€ training_iterations.png- **`dashboard/app.py`** - Interactive forecasting dashboard

â”‚- **`models/`** - All 267 trained models

â”œâ”€â”€ ğŸ“š docs/                     # Documentation

â”‚   â”œâ”€â”€ DASHBOARD_GUIDE.md       # Dashboard usage instructions### **Optimization Results**

â”‚   â”œâ”€â”€ DASHBOARD_USER_GUIDE.md  # Detailed user guide- **`scripts/optimization/`** - Hyperparameter tuning methodology

â”‚   â”œâ”€â”€ MODEL_SELECTION_GUIDE.md # Model selection methodology- **`reports/figures/`** - Performance visualization charts

â”‚   â”œâ”€â”€ PERCENTAGE_KPI_GUIDE.md  # KPI-specific optimizations

â”‚   â””â”€â”€ STATISTICAL_VALIDATION_RESPONSE.md # Validation methodology### **Documentation**

â”‚- **`docs/`** - Complete user guides and model selection

â”œâ”€â”€ ğŸ“ notebooks/                # Analysis Notebooks- **`README.md`** - Project overview and instructions

â”‚   â”œâ”€â”€ eda.ipynb               # Exploratory data analysis

â”‚   â””â”€â”€ model_evaluation_methodology.ipynb # Evaluation methodology### **Quick Demo**

â”‚- **`run_dashboard.bat`** - One-click dashboard startup

â”œâ”€â”€ ğŸ§ª tests/                    # Test Suite- **`data/processed/mta_model.parquet`** - Ready-to-use dataset

â”‚   â””â”€â”€ test_percentage_prediction.py # Model validation tests

â”‚## Quick Start Commands

â”œâ”€â”€ ğŸ“¦ dev/                      # Development Scripts (Archived)

â”‚   â”œâ”€â”€ fyp_optimization_strategy.py    # Optimization strategy```bash

â”‚   â”œâ”€â”€ hyperparameter_recommendations.py # Parameter recommendations# Install dependencies

â”‚   â””â”€â”€ linear_regression_quick_win.py  # Linear regression enhancementspip install -r requirements.txt

â”‚

â”œâ”€â”€ ğŸ“ archive/                  # Historical Analysis (Archived)# Launch dashboard

â”‚   â”œâ”€â”€ architecture_optimization_log.md # Optimization history./run_dashboard.bat

â”‚   â””â”€â”€ eda_summary.md                   # Historical EDA summary

â”‚# Run training pipeline

â”œâ”€â”€ ğŸ“‹ README.md                 # Project overview â­python src/train_ml.py

â”œâ”€â”€ ğŸ“¦ requirements.txt          # Dependencies â­

â”œâ”€â”€ ğŸš€ run_dashboard.bat         # One-click dashboard startup â­# Generate performance analysis

â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md      # This filepython scripts/analysis/analyze_model_performance.py

â””â”€â”€ âš™ï¸ Makefile                 # Build automation```

```

## File Usage Priority

## **Production Components** â­

### **High Priority**

### **Core System**1. `src/train_ml.py` - Core training implementation

1. **`dashboard/app.py`** - Professional analytics dashboard with Apple-inspired design2. `dashboard/app.py` - Interactive demonstration

2. **`src/train_ml.py`** - Optimized ML training (RandomForest best performer)3. `reports/figures/` - Performance visualizations

3. **`models/`** - 267 trained models (3 ML + 264 time series)4. `docs/` - Documentation for presentation

4. **`data/processed/mta_model.parquet`** - Clean, feature-engineered dataset

### **Medium Priority**

### **Performance Documentation**1. `scripts/optimization/` - Shows methodology

1. **`reports/model_performance_overview_updated.md`** - Executive summary with corrected metrics2. `models/` - Trained model artifacts

2. **`reports/figures/`** - Professional performance charts3. `data/processed/` - Clean dataset

3. **`docs/DASHBOARD_USER_GUIDE.md`** - Complete user instructions

### **Low Priority**

### **Key Achievements** ğŸ¯1. `scripts/analysis/` - Development tools

- **5x Performance Improvement**: Percentage KPI prediction (MAE: 0.335 vs 1.732)2. `scripts/data_processing/` - Data preparation

- **Professional UI**: Apple-inspired dashboard with confidence intervals3. `notebooks/` - Exploratory analysis

- **Comprehensive ML Pipeline**: 45 engineered features, optimized hyperparameters

- **Statistical Validation**: Bootstrap confidence intervals for ML, native for time series---

## **Quick Start Commands**

```bash
# Launch professional dashboard
./run_dashboard.bat

# Install dependencies
pip install -r requirements.txt

# Run optimized ML training
python src/train_ml.py

# Generate performance analysis
python scripts/analysis/analyze_model_performance.py
```

## **Performance Summary**

| Model | MAE | Status | Performance vs Best |
|-------|-----|--------|-------------------|
| **RandomForest** | **13,637** | âœ… **Best Performer** | **Baseline** |
| XGBoost | 39,885 | âš ï¸ Secondary | +192% |
| LinearRegression | 130,912 | ğŸ“Š Baseline | +860% |

**Total Models Trained**: 267 (3 ML + 264 Time Series)
**Dataset**: 45 engineered features, March 2017 cutoff
**Optimization**: Unified RandomForest approach, removed specialized predictors

---

*Project cleaned and organized - September 15, 2025*